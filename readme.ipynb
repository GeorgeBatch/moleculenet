{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GeorgeBatch/learning-ligand/blob/master/readme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKlFm8apnGE5"
   },
   "source": [
    "# Physical Chemistry datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-U67ensXkNJ"
   },
   "source": [
    "This repository aims to show the process of exploring how varying **feature sets**, **train-validation-test splits**, and **models** changes the prediction performance on the regression tasks for [Physical Chemistry datasets](http://moleculenet.ai/datasets-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1t3KagieX1Nn"
   },
   "source": [
    "# Set-up\n",
    "\n",
    "To make the reproduction process as simple as possible, clone this repository (`moleculenet`) to your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLypdi-bn9gL"
   },
   "source": [
    "## Directory\n",
    "\n",
    "Choose a directory, where you will store the data and the code to reproduce the results. Organize the directory in it as shown below.\n",
    "\n",
    "All the files in the `data` folder are either downloaded from the [Moleculenet web page](http://moleculenet.ai/). You can download the data from the [datasets page](http://moleculenet.ai/datasets-1).\n",
    "\n",
    "Populate the data directory with the following files:\n",
    "\n",
    "- from the FreeSolv folder: `SAMPL.csv`, `FreeSolv_README`\n",
    "- from the ESOL folder: `delaney-processed.csv`, `ESOL_README`\n",
    "- from the lipophilicity folder: `Lipophilicity.csv`, `Lipo_README`\n",
    "\n",
    "```\n",
    "- moleculenet\n",
    "  |\n",
    "  ---- data\n",
    "  |\n",
    "  ---- figures\n",
    "  |\n",
    "  ---- notebooks\n",
    "  |\n",
    "  ---- scripts\n",
    "  |\n",
    "  ---- results\n",
    "  |\n",
    "  ---- environment.yml\n",
    "```\n",
    "\n",
    "Rename the csv files as follows:\n",
    "\n",
    "- `SAMPL.csv` $\\to$ `freesolv_original.csv`\n",
    "- `delaney-processed.csv` $\\to$ `esol_original.csv`\n",
    "- `Lipophilicity.csv` $\\to$ `lipophilicity_original.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jO_9B_rInjpC"
   },
   "source": [
    "## Environment\n",
    "\n",
    "In the `moleculenet` directory create project envoronment from the environment.yml file using:\n",
    "```\n",
    ">>> conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "Environment's name is `batch-msc`, and we activate it using:\n",
    "```\n",
    ">>> conda activate batch-msc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvhHdLaAzImd"
   },
   "source": [
    "## Standardise the file names and column names\n",
    "\n",
    "We will need to get hold of IDs/Names, Smiles, and measured label values for all 3 datasets. We will produce 3 csv files with the following coloumns to standardise the future work:\n",
    "\n",
    "Run the following commands to get them in the `scripts` directory:\n",
    "\n",
    "```\n",
    ">>> python get_original_id_smiles_labels_lipophilicity.py \n",
    ">>> python get_original_id_smiles_labels_esol.py \n",
    ">>> python get_original_id_smiles_labels_freesolv.py \n",
    "```\n",
    "\n",
    "The output files are in the `../data/` directory:\n",
    "- `esol_original_IdSmilesLabels.csv`, `esol_original_extra_features.csv`\n",
    "- `freesolv_original_IdSmilesLabels.csv`\n",
    "- `lipophilicity_original_IdSmilesLabels.csv`\n",
    "\n",
    "**Note:** data for ESOL dataset also contained extra features which we also saved here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bssblb__rxNb"
   },
   "source": [
    "## Create .csv files with ECFP-4, ECFP-6 fingerprints for all datasets*smile-string combinations\n",
    "\n",
    "We produce the files with ECFP-4, ECFP-6 fingerprints for all datasets*smile-string combinations. We do it once and never worry anout it in the future.\n",
    "\n",
    "Run the following command `scripts` directory:\n",
    "```\n",
    ">>> python get_all_fingerprints_for_all_datasets.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XsXi7_tI7aZG"
   },
   "source": [
    "## Create .csv files with RDKit molecular descriptors for all datasets*smile-string combinations\n",
    "\n",
    "We produce the files with ECFP-4, ECFP-6 fingerprints for all datasets*smile-string combinations. We do it once and never worry anout it in the future.\n",
    "\n",
    "Run the following command `scripts` directory:\n",
    "```\n",
    ">>> python get_rdkit_descriptors_for_all_datasets.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0Q0nPRUyt-4"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "readme.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:batch-msc] *",
   "language": "python",
   "name": "conda-env-batch-msc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
